## Scalable LLM Chatbot with Context Compression and Cost-Aware Routing

A chatbot built on two different models (small and large) with the following features:

- Context compression via rolling message summarization with structured message
- Cost-aware model routing based on confidence threshold
- Bounded token growth for long conversations
- Quantitative evaluation of latency and costs
